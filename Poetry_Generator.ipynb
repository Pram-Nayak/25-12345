{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VG-Pjx36GYwj","executionInfo":{"status":"ok","timestamp":1739245353683,"user_tz":-330,"elapsed":23032,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}},"outputId":"d014c8a3-f482-40cd-a82e-c73db3252205"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"EsgxJ10m5ujD","executionInfo":{"status":"ok","timestamp":1739245410150,"user_tz":-330,"elapsed":3,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"outputs":[],"source":["\"\"\"\n","import numpy as np: Imports the NumPy library for numerical computations.\n","import string: Imports the string module for string operations.\n","np.random.seed(1234): This line sets the random seed for NumPy's random number generator.\n","Setting the seed ensures that the random numbers generated are reproducible.\n","\"\"\"\n","import numpy as np\n","import string\n","\n","np.random.seed(1234)"]},{"cell_type":"code","source":["\"\"\"\n","initial = {}: Creates an empty dictionary to store the frequency of words appearing at the beginning of a phrase.\n","first_order = {}: Creates an empty dictionary to store the frequency of the second word given the first word.\n","second_order = {}: Creates an empty dictionary to store the frequency of the third word given the first two words.\n","\"\"\"\n","initial = {} # start of a phrase\n","first_order = {} # second word only\n","second_order = {}\n","third_order = {}"],"metadata":{"id":"uUXoDGlU56MW","executionInfo":{"status":"ok","timestamp":1739250080787,"user_tz":-330,"elapsed":4,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","This block defines a function called remove_punctuation that takes a string s as input.\n","It removes punctuation from the input string using the translate method and returns the modified string.\n","\"\"\"\n","def remove_punctuation(s):\n","    return s.translate(str.maketrans('','',string.punctuation))"],"metadata":{"id":"pG8nvs2A6KGj","executionInfo":{"status":"ok","timestamp":1739245438996,"user_tz":-330,"elapsed":1,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","This block defines a function called add2dict which takes a dictionary d, a key k, and a value v as input.\n","If the key k is not already in the dictionary d, it creates a new list for that key.\n","It then appends the value v to the list associated with the key k in the dictionary d.\n","\"\"\"\n","def add2dict(d, k, v):\n","  if k not in d:\n","    d[k] = []\n","  d[k].append(v)\n","\n","# [cat, cat, dog, dog, dog, dog, dog, mouse, ...]"],"metadata":{"id":"Jd5BM9nw6Y4V","executionInfo":{"status":"ok","timestamp":1739245479750,"user_tz":-330,"elapsed":39,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","This block reads a text file line by line.\n","For each line, it removes punctuation, converts it to lowercase, and splits it into individual words (tokens).\n","It then iterates through the tokens to build the dictionaries initial, first_order, and second_order.\n","\"\"\"\n","for line in open('/content/drive/MyDrive/Colab Notebooks2/NLP/Lab5/robert_frost (1).txt'):\n","  tokens = remove_punctuation(line.rstrip().lower()).split()\n","\n","  T = len(tokens)\n","  for i in range(T):\n","    t = tokens[i]\n","    if i == 0:\n","      # measure the distribution of the first word\n","      initial[t] = initial.get(t, 0.) + 1\n","    else:\n","      t_1 = tokens[i-1]\n","      if i == T - 1:\n","        # measure probability of ending the line\n","        add2dict(second_order, (t_1, t), 'END')\n","      if i == 1:\n","        # measure distribution of second word\n","        # given only first word\n","        add2dict(first_order, t_1, t)\n","      else:\n","        t_2 = tokens[i-2]\n","        add2dict(second_order, (t_2, t_1), t)"],"metadata":{"id":"mpIaDx_26a95","executionInfo":{"status":"ok","timestamp":1739245484244,"user_tz":-330,"elapsed":169,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","These blocks normalize the frequency counts in the initial, first_order, and second_order dictionaries to obtain probabilities.\n","They convert the lists of words into dictionaries of probabilities, where each word is associated with its probability of occurrence.\n","\"\"\"\n","# normalize the distributions\n","initial_total = sum(initial.values())\n","for t, c in initial.items():\n","    initial[t] = c / initial_total"],"metadata":{"id":"UOIqCm8Q6gED","executionInfo":{"status":"ok","timestamp":1739245487612,"user_tz":-330,"elapsed":2,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","sample_word function: This function takes a dictionary of probabilities d as input.\n","It randomly selects a word from the dictionary based on the probabilities assigned to each word.\n","generate function: This function generates text by sampling words based on the probabilities learned from the input text file.\n","It uses the sample_word function to select words and build sentences.\n","\"\"\"\n","# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n","# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n","\n","def list2pdict(ts):\n","  # turn each list of possibilities into a dictionary of probabilities\n","  d = {}\n","  n = len(ts)\n","  for t in ts:\n","    d[t] = d.get(t, 0.) + 1\n","  for t, c in d.items():\n","    d[t] = c / n\n","  return d"],"metadata":{"id":"-5nvUJ5z6kw4","executionInfo":{"status":"ok","timestamp":1739245490582,"user_tz":-330,"elapsed":4,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","for t_1, ts in first_order.items():\n","  # replace list with dictionary of probabilities\n","  first_order[t_1] = list2pdict(ts)"],"metadata":{"id":"Cw2dyiVZ60yH","executionInfo":{"status":"ok","timestamp":1739245492782,"user_tz":-330,"elapsed":2,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["for k, ts in second_order.items():\n","  second_order[k] = list2pdict(ts)"],"metadata":{"id":"Mt7enPlu65CB","executionInfo":{"status":"ok","timestamp":1739245495099,"user_tz":-330,"elapsed":9,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def sample_word(d):\n","  # print \"d:\", d\n","  p0 = np.random.random()\n","  # print \"p0:\", p0\n","  cumulative = 0\n","  for t, p in d.items():\n","    cumulative += p\n","    if p0 < cumulative:\n","      return t\n","  assert(False) # should never get here"],"metadata":{"id":"Br1VW7f168kn","executionInfo":{"status":"ok","timestamp":1739245496611,"user_tz":-330,"elapsed":2,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def generate():\n","  for i in range(4): # generate 4 lines\n","    sentence = []\n","\n","    # initial word\n","    w0 = sample_word(initial)\n","    sentence.append(w0)\n","\n","    # sample second word\n","    w1 = sample_word(first_order[w0])\n","    sentence.append(w1)\n","\n","    # second-order transitions until END\n","    while True:\n","      w2 = sample_word(second_order[(w0, w1)])\n","      if w2 == 'END':\n","        break\n","      sentence.append(w2)\n","      w0 = w1\n","      w1 = w2\n","    print(' '.join(sentence))"],"metadata":{"id":"f1zpAXfo7FT5","executionInfo":{"status":"ok","timestamp":1739245498110,"user_tz":-330,"elapsed":2,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","generate() function to start the text generation process.\n","\"\"\"\n","generate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8Wicch67GgK","outputId":"7e9b0958-142e-4db2-d9fa-6066541c8917","executionInfo":{"status":"ok","timestamp":1739246866963,"user_tz":-330,"elapsed":9,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["i know\n","up to pass a winter eve\n","to make them out\n","and then someone\n"]}]},{"cell_type":"markdown","source":["Purpose and Importance:\n","\n","This code implements a statistical language model, specifically a second-order Markov model, for text generation. Its core function is to learn patterns from an input text and then use these patterns to generate new text that resembles the original text in style and structure.\n","\n","Why It's Required:\n","\n","Learning Language Patterns: The code analyzes the input text to understand the frequency and sequence of words. It builds probability distributions for words appearing at the beginning of sentences, following specific words, and following pairs of words. This learning process captures the underlying language patterns present in the text.\n","\n","Generating Realistic Text: Using the learned probabilities, the code can generate new text by sampling words based on their likelihood of occurrence in a given context. This allows it to create sentences that are grammatically plausible and stylistically similar to the input text.\n","\n","Applications: Statistical language models like this have various applications, including:\n","\n","Text prediction: Suggesting the next word as you type, like in smartphone keyboards.\n","Machine translation: Helping to translate text from one language to another by considering word sequences and probabilities.\n","Speech recognition: Converting spoken language into text by predicting the most likely words based on acoustic signals.\n","Text summarization: Creating condensed versions of text by identifying and extracting the most important information.\n","Chatbots: Building conversational agents that can generate more human-like and contextually relevant responses.\n","Usage:\n","\n","The code takes a text file as input, which is used to train the language model. After training, it can generate new text by:\n","\n","Randomly selecting a starting word based on the probabilities in the initial dictionary.\n","Choosing the next word based on the probabilities in the first_order dictionary, given the previous word.\n","Continuing to generate words based on the probabilities in the second_order dictionary, given the previous two words.\n","The process ends when the model generates the 'END' token, indicating the end of a sentence.\n","Importance:\n","\n","Statistical language models are important tools for understanding and working with natural language data. They provide a way to capture the statistical regularities of language, allowing us to perform tasks such as text generation, prediction, and analysis. By learning from data, these models can help us to build systems that can understand and interact with human language in a more intelligent and meaningful way.\n","\n","In the context of your provided code, it demonstrates a simple yet powerful technique for text generation. By learning from the style and structure of Robert Frost's poems, the model can generate new text that resembles his writing. While the generated text might not be perfect poetry, it shows the potential of statistical language models to learn and mimic the patterns of human language."],"metadata":{"id":"Vilw90gMMYll"}},{"cell_type":"code","source":["#increase the order  for our first sem project report\n"],"metadata":{"id":"Vsrkrswy7JeJ","executionInfo":{"status":"ok","timestamp":1739245502279,"user_tz":-330,"elapsed":6,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["for line in open('/content/drive/MyDrive/Colab Notebooks2/NLP/Lab5/robert_frost (1).txt'):\n","  tokens = remove_punctuation(line.rstrip().lower()).split()\n","\n","  T = len(tokens)\n","  for i in range(T):\n","    t = tokens[i]\n","    if i == 0:\n","      # measure the distribution of the first word\n","      initial[t] = initial.get(t, 0.) + 1\n","    else:\n","      t_1 = tokens[i-1]\n","      if i == T - 1:\n","        # measure probability of ending the line\n","        add2dict(third_order, (tokens[i-2] if i>1 else None,t_1, t), 'END') #Update here for third-order\n","      if i == 1:\n","        # measure distribution of second word\n","        # given only first word\n","        add2dict(first_order, t_1, t)\n","      elif i==2:\n","        t_2 = tokens[i-2]\n","        add2dict(second_order, (t_2, t_1), t)\n","      else:\n","        t_2 = tokens[i-2]\n","        t_3 = tokens[i-3]\n","        add2dict(third_order, (t_3,t_2, t_1), t)  #Update here for third-order"],"metadata":{"id":"0ckwNsL6YciK","executionInfo":{"status":"ok","timestamp":1739250084488,"user_tz":-330,"elapsed":277,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["for k, ts in third_order.items():\n","  third_order[k] = list2pdict(ts)"],"metadata":{"id":"ACmiuMSjYj8G","executionInfo":{"status":"ok","timestamp":1739250091544,"user_tz":-330,"elapsed":20,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def generate():\n","  for i in range(4): # generate 4 lines\n","    sentence = []\n","\n","    # initial word\n","    w0 = sample_word(initial)\n","    sentence.append(w0)\n","\n","    # sample second word\n","    w1 = sample_word(first_order[w0])\n","    sentence.append(w1)\n","\n","    # sample third word\n","    if (None,w0,w1) in third_order:\n","      w2 = sample_word(third_order[(None,w0,w1)]) #Update here for third-order\n","    else:\n","      w2 = sample_word(second_order[(w0, w1)])\n","    sentence.append(w2)\n","\n","    # third-order transitions until END\n","\n","    while True:\n","      if (w0,w1,w2) in third_order:\n","        w3 = sample_word(third_order[(w0, w1,w2)]) #Update here for third-order\n","      else:\n","        w3 = sample_word(second_order[(w1,w2)])\n","\n","      if w3 == 'END':\n","        break\n","      sentence.append(w3)\n","      w0 = w1\n","      w1 = w2\n","      w2 = w3\n","    print(' '.join(sentence))"],"metadata":{"id":"2_Xa2C3WYl_G","executionInfo":{"status":"ok","timestamp":1739250099380,"user_tz":-330,"elapsed":39,"user":{"displayName":"pratham nayak","userId":"05731916045779423139"}}},"execution_count":20,"outputs":[]}]}